{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711a266f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7129300520</td>\n",
       "      <td>20141013T000000</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6414100192</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5631500400</td>\n",
       "      <td>20150225T000000</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2487200875</td>\n",
       "      <td>20141209T000000</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1954400510</td>\n",
       "      <td>20150218T000000</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id             date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "0  7129300520  20141013T000000  221900.0         3       1.00         1180   \n",
       "1  6414100192  20141209T000000  538000.0         3       2.25         2570   \n",
       "2  5631500400  20150225T000000  180000.0         2       1.00          770   \n",
       "3  2487200875  20141209T000000  604000.0         4       3.00         1960   \n",
       "4  1954400510  20150218T000000  510000.0         3       2.00         1680   \n",
       "\n",
       "   sqft_lot  floors  waterfront  view  ...  grade  sqft_above  sqft_basement  \\\n",
       "0      5650     1.0           0     0  ...      7        1180              0   \n",
       "1      7242     2.0           0     0  ...      7        2170            400   \n",
       "2     10000     1.0           0     0  ...      6         770              0   \n",
       "3      5000     1.0           0     0  ...      7        1050            910   \n",
       "4      8080     1.0           0     0  ...      8        1680              0   \n",
       "\n",
       "   yr_built  yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "0      1955             0    98178  47.5112 -122.257           1340   \n",
       "1      1951          1991    98125  47.7210 -122.319           1690   \n",
       "2      1933             0    98028  47.7379 -122.233           2720   \n",
       "3      1965             0    98136  47.5208 -122.393           1360   \n",
       "4      1987             0    98074  47.6168 -122.045           1800   \n",
       "\n",
       "   sqft_lot15  \n",
       "0        5650  \n",
       "1        7639  \n",
       "2        8062  \n",
       "3        5000  \n",
       "4        7503  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "#import folium\n",
    "#from folium.plugins import HeatMap\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Details':[],\n",
    "                           'Root Mean Squared Error (RMSE)':[],\n",
    "                           'R-squared (training)':[],\n",
    "                           'Adjusted R-squared (training)':[],\n",
    "                           'R-squared (test)':[],\n",
    "                           'Adjusted R-squared (test)':[],\n",
    "                           '5-Fold Cross Validation':[]})\n",
    "\n",
    "df = pd.read_csv('house builder.csv')\n",
    "#df.describe()\n",
    "#df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "169ad1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjustedR2(r2,n,k):\n",
    "    return r2-(k-1)/(n-k)*(1-r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f629a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Price for Test Data: 539744.130\n",
      "Intercept: -47235.811302901246\n",
      "Coefficient: [282.2468152]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model Details  Root Mean Squared Error (RMSE)  \\\n",
       "0  Simple Linear Regression       -                      254289.149   \n",
       "\n",
       "   R-squared (training) Adjusted R-squared (training)  R-squared (test)  \\\n",
       "0                 0.492                             -             0.496   \n",
       "\n",
       "  Adjusted R-squared (test)  5-Fold Cross Validation  \n",
       "0                         -                    0.491  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#%%capture\n",
    "train_data,test_data = train_test_split(df,train_size = 0.8,random_state=3)\n",
    "\n",
    "lr = linear_model.LinearRegression()\n",
    "X_train = np.array(train_data['sqft_living'], dtype=pd.Series).reshape(-1,1)\n",
    "y_train = np.array(train_data['price'], dtype=pd.Series)\n",
    "lr.fit(X_train,y_train)\n",
    "\n",
    "X_test = np.array(test_data['sqft_living'], dtype=pd.Series).reshape(-1,1)\n",
    "y_test = np.array(test_data['price'], dtype=pd.Series)\n",
    "\n",
    "pred = lr.predict(X_test)\n",
    "rmsesm = float(format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f'))\n",
    "rtrsm = float(format(lr.score(X_train, y_train),'.3f'))\n",
    "rtesm = float(format(lr.score(X_test, y_test),'.3f'))\n",
    "cv = float(format(cross_val_score(lr,df[['sqft_living']],df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "print (\"Average Price for Test Data: {:.3f}\".format(y_test.mean()))\n",
    "print('Intercept: {}'.format(lr.intercept_))\n",
    "print('Coefficient: {}'.format(lr.coef_))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['Simple Linear Regression','-',rmsesm,rtrsm,'-',rtesm,'-',cv]\n",
    "evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9de7a985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>2.161300e+04</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "      <td>21613.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.580302e+09</td>\n",
       "      <td>5.400881e+05</td>\n",
       "      <td>3.370842</td>\n",
       "      <td>2.114757</td>\n",
       "      <td>2079.899736</td>\n",
       "      <td>1.510697e+04</td>\n",
       "      <td>1.494309</td>\n",
       "      <td>0.007542</td>\n",
       "      <td>0.234303</td>\n",
       "      <td>3.409430</td>\n",
       "      <td>7.656873</td>\n",
       "      <td>1788.390691</td>\n",
       "      <td>291.509045</td>\n",
       "      <td>1971.005136</td>\n",
       "      <td>84.402258</td>\n",
       "      <td>98077.939805</td>\n",
       "      <td>47.560053</td>\n",
       "      <td>-122.213896</td>\n",
       "      <td>1986.552492</td>\n",
       "      <td>12768.455652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.876566e+09</td>\n",
       "      <td>3.671272e+05</td>\n",
       "      <td>0.930062</td>\n",
       "      <td>0.770163</td>\n",
       "      <td>918.440897</td>\n",
       "      <td>4.142051e+04</td>\n",
       "      <td>0.539989</td>\n",
       "      <td>0.086517</td>\n",
       "      <td>0.766318</td>\n",
       "      <td>0.650743</td>\n",
       "      <td>1.175459</td>\n",
       "      <td>828.090978</td>\n",
       "      <td>442.575043</td>\n",
       "      <td>29.373411</td>\n",
       "      <td>401.679240</td>\n",
       "      <td>53.505026</td>\n",
       "      <td>0.138564</td>\n",
       "      <td>0.140828</td>\n",
       "      <td>685.391304</td>\n",
       "      <td>27304.179631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>5.200000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>290.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.155900</td>\n",
       "      <td>-122.519000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>651.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.123049e+09</td>\n",
       "      <td>3.219500e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>1427.000000</td>\n",
       "      <td>5.040000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98033.000000</td>\n",
       "      <td>47.471000</td>\n",
       "      <td>-122.328000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>5100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.904930e+09</td>\n",
       "      <td>4.500000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>7.618000e+03</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1560.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98065.000000</td>\n",
       "      <td>47.571800</td>\n",
       "      <td>-122.230000</td>\n",
       "      <td>1840.000000</td>\n",
       "      <td>7620.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.308900e+09</td>\n",
       "      <td>6.450000e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2550.000000</td>\n",
       "      <td>1.068800e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2210.000000</td>\n",
       "      <td>560.000000</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98118.000000</td>\n",
       "      <td>47.678000</td>\n",
       "      <td>-122.125000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10083.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.900000e+09</td>\n",
       "      <td>7.700000e+06</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>13540.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>9410.000000</td>\n",
       "      <td>4820.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>6210.000000</td>\n",
       "      <td>871200.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price      bedrooms     bathrooms   sqft_living  \\\n",
       "count  2.161300e+04  2.161300e+04  21613.000000  21613.000000  21613.000000   \n",
       "mean   4.580302e+09  5.400881e+05      3.370842      2.114757   2079.899736   \n",
       "std    2.876566e+09  3.671272e+05      0.930062      0.770163    918.440897   \n",
       "min    1.000102e+06  7.500000e+04      0.000000      0.000000    290.000000   \n",
       "25%    2.123049e+09  3.219500e+05      3.000000      1.750000   1427.000000   \n",
       "50%    3.904930e+09  4.500000e+05      3.000000      2.250000   1910.000000   \n",
       "75%    7.308900e+09  6.450000e+05      4.000000      2.500000   2550.000000   \n",
       "max    9.900000e+09  7.700000e+06     33.000000      8.000000  13540.000000   \n",
       "\n",
       "           sqft_lot        floors    waterfront          view     condition  \\\n",
       "count  2.161300e+04  21613.000000  21613.000000  21613.000000  21613.000000   \n",
       "mean   1.510697e+04      1.494309      0.007542      0.234303      3.409430   \n",
       "std    4.142051e+04      0.539989      0.086517      0.766318      0.650743   \n",
       "min    5.200000e+02      1.000000      0.000000      0.000000      1.000000   \n",
       "25%    5.040000e+03      1.000000      0.000000      0.000000      3.000000   \n",
       "50%    7.618000e+03      1.500000      0.000000      0.000000      3.000000   \n",
       "75%    1.068800e+04      2.000000      0.000000      0.000000      4.000000   \n",
       "max    1.651359e+06      3.500000      1.000000      4.000000      5.000000   \n",
       "\n",
       "              grade    sqft_above  sqft_basement      yr_built  yr_renovated  \\\n",
       "count  21613.000000  21613.000000   21613.000000  21613.000000  21613.000000   \n",
       "mean       7.656873   1788.390691     291.509045   1971.005136     84.402258   \n",
       "std        1.175459    828.090978     442.575043     29.373411    401.679240   \n",
       "min        1.000000    290.000000       0.000000   1900.000000      0.000000   \n",
       "25%        7.000000   1190.000000       0.000000   1951.000000      0.000000   \n",
       "50%        7.000000   1560.000000       0.000000   1975.000000      0.000000   \n",
       "75%        8.000000   2210.000000     560.000000   1997.000000      0.000000   \n",
       "max       13.000000   9410.000000    4820.000000   2015.000000   2015.000000   \n",
       "\n",
       "            zipcode           lat          long  sqft_living15     sqft_lot15  \n",
       "count  21613.000000  21613.000000  21613.000000   21613.000000   21613.000000  \n",
       "mean   98077.939805     47.560053   -122.213896    1986.552492   12768.455652  \n",
       "std       53.505026      0.138564      0.140828     685.391304   27304.179631  \n",
       "min    98001.000000     47.155900   -122.519000     399.000000     651.000000  \n",
       "25%    98033.000000     47.471000   -122.328000    1490.000000    5100.000000  \n",
       "50%    98065.000000     47.571800   -122.230000    1840.000000    7620.000000  \n",
       "75%    98118.000000     47.678000   -122.125000    2360.000000   10083.000000  \n",
       "max    98199.000000     47.777600   -121.315000    6210.000000  871200.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dm=df.copy()\n",
    "df_dm.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f94dcffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# just take the year from the date column\n",
    "df_dm['sales_yr']=df_dm['date'].astype(str).str[:4]\n",
    "\n",
    "# add the age of the buildings when the houses were sold as a new column\n",
    "df_dm['age']=df_dm['sales_yr'].astype(int)-df_dm['yr_built']\n",
    "# add the age of the renovation when the houses were sold as a new column\n",
    "df_dm['age_rnv']=0\n",
    "df_dm['age_rnv']=df_dm['sales_yr'][df_dm['yr_renovated']!=0].astype(int)-df_dm['yr_renovated'][df_dm['yr_renovated']!=0]\n",
    "df_dm['age_rnv'][df_dm['age_rnv'].isnull()]=0\n",
    "\n",
    "# partition the age into bins\n",
    "bins = [-2,0,5,10,25,50,75,100,100000]\n",
    "labels = ['<1','1-5','6-10','11-25','26-50','51-75','76-100','>100']\n",
    "df_dm['age_binned'] = pd.cut(df_dm['age'], bins=bins, labels=labels)\n",
    "# partition the age_rnv into bins\n",
    "bins = [-2,0,5,10,25,50,75,100000]\n",
    "labels = ['<1','1-5','6-10','11-25','26-50','51-75','>75']\n",
    "df_dm['age_rnv_binned'] = pd.cut(df_dm['age_rnv'], bins=bins, labels=labels)\n",
    "\n",
    "# histograms for the binned columns\n",
    "f, axes = plt.subplots(1, 2,figsize=(15,5))\n",
    "p1=sns.countplot(df_dm['age_binned'],ax=axes[0])\n",
    "for p in p1.patches:\n",
    "    height = p.get_height()\n",
    "    p1.text(p.get_x()+p.get_width()/2,height + 50,height,ha=\"center\")   \n",
    "p2=sns.countplot(df_dm['age_rnv_binned'],ax=axes[1])\n",
    "sns.despine(left=True, bottom=True)\n",
    "for p in p2.patches:\n",
    "    height = p.get_height()\n",
    "    p2.text(p.get_x()+p.get_width()/2,height + 200,height,ha=\"center\")\n",
    "    \n",
    "axes[0].set(xlabel='Age')\n",
    "axes[0].yaxis.tick_left()\n",
    "axes[1].yaxis.set_label_position(\"right\")\n",
    "axes[1].yaxis.tick_right()\n",
    "axes[1].set(xlabel='Renovation Age');\n",
    "\n",
    "# transform the factor values to be able to use in the model\n",
    "df_dm = pd.get_dummies(df_dm, columns=['age_binned','age_rnv_binned'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d3af9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: -57221293.13485892\n",
      "Coefficients: [-5.68950279e+04  1.13310062e+04  3.18389287e+02 -2.90807628e-01\n",
      " -5.79609821e+03  5.84022824e+02]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model            Details  \\\n",
       "1     Multiple Regression-1  selected features   \n",
       "0  Simple Linear Regression                  -   \n",
       "\n",
       "   Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "1                      248514.011                 0.514   \n",
       "0                      254289.149                 0.492   \n",
       "\n",
       "  Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "1                         0.514             0.519                     0.518   \n",
       "0                             -             0.496                         -   \n",
       "\n",
       "   5-Fold Cross Validation  \n",
       "1                    0.512  \n",
       "0                    0.491  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_dm,test_data_dm = train_test_split(df_dm,train_size = 0.8,random_state=3)\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','zipcode']\n",
    "complex_model_1 = linear_model.LinearRegression()\n",
    "complex_model_1.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "print('Intercept: {}'.format(complex_model_1.intercept_))\n",
    "print('Coefficients: {}'.format(complex_model_1.coef_))\n",
    "\n",
    "pred = complex_model_1.predict(test_data_dm[features])\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_1.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_1.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_1.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_1.score(test_data_dm[features],test_data['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv = float(format(cross_val_score(complex_model_1,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['Multiple Regression-1','selected features',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "evaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a9355b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 14932064.45670693\n",
      "Coefficients: [-3.74523328e+04  4.83495326e+04  1.71684976e+02 -2.31081061e-01\n",
      "  1.03590806e+04  5.56285921e+05  4.78399848e+04  1.24143045e+05\n",
      " -8.88123227e+04 -1.05756567e+05 -1.04723750e+05 -1.35898725e+05\n",
      " -5.37336956e+04  8.41048129e+04  1.84153081e+05  2.20667166e+05\n",
      " -1.60046391e+02]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multiple Regression-2</td>\n",
       "      <td>selected features</td>\n",
       "      <td>209712.753</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model            Details  \\\n",
       "2     Multiple Regression-2  selected features   \n",
       "1     Multiple Regression-1  selected features   \n",
       "0  Simple Linear Regression                  -   \n",
       "\n",
       "   Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "2                      209712.753                 0.652   \n",
       "1                      248514.011                 0.514   \n",
       "0                      254289.149                 0.492   \n",
       "\n",
       "  Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "2                         0.652             0.657                     0.656   \n",
       "1                         0.514             0.519                     0.518   \n",
       "0                             -             0.496                         -   \n",
       "\n",
       "   5-Fold Cross Validation  \n",
       "2                    0.648  \n",
       "1                    0.512  \n",
       "0                    0.491  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "             'grade','age_binned_<1', 'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', \n",
    "             'age_binned_26-50', 'age_binned_51-75','age_binned_76-100', 'age_binned_>100',\n",
    "             'zipcode']\n",
    "complex_model_2 = linear_model.LinearRegression()\n",
    "complex_model_2.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "print('Intercept: {}'.format(complex_model_2.intercept_))\n",
    "print('Coefficients: {}'.format(complex_model_2.coef_))\n",
    "\n",
    "pred = complex_model_2.predict(test_data_dm[features])\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_2.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_2.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_2.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_2.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv = float(format(cross_val_score(complex_model_2,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['Multiple Regression-2','selected features',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "evaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "282ac58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 7580919.94036692\n",
      "Coefficients: [-3.51323305e+04  4.25821114e+04  1.10705020e+02  1.13581822e-01\n",
      "  6.82992716e+03  5.61794985e+05  5.28174040e+04  2.48918356e+04\n",
      "  9.57708783e+04  7.01998424e+01  4.05051775e+01 -2.70948034e+03\n",
      "  2.26715091e+01 -5.80427853e+02  5.98629230e+05 -2.08875497e+05\n",
      "  2.32857416e+01 -3.75353459e-01]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiple Regression-3</td>\n",
       "      <td>all features, no preprocessing</td>\n",
       "      <td>193693.989</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multiple Regression-2</td>\n",
       "      <td>selected features</td>\n",
       "      <td>209712.753</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model                         Details  \\\n",
       "3     Multiple Regression-3  all features, no preprocessing   \n",
       "2     Multiple Regression-2               selected features   \n",
       "1     Multiple Regression-1               selected features   \n",
       "0  Simple Linear Regression                               -   \n",
       "\n",
       "   Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "3                      193693.989                 0.698   \n",
       "2                      209712.753                 0.652   \n",
       "1                      248514.011                 0.514   \n",
       "0                      254289.149                 0.492   \n",
       "\n",
       "  Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "3                         0.697             0.708                     0.707   \n",
       "2                         0.652             0.657                     0.656   \n",
       "1                         0.514             0.519                     0.518   \n",
       "0                             -             0.496                         -   \n",
       "\n",
       "   5-Fold Cross Validation  \n",
       "3                    0.695  \n",
       "2                    0.648  \n",
       "1                    0.512  \n",
       "0                    0.491  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "            'condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "complex_model_3 = linear_model.LinearRegression()\n",
    "complex_model_3.fit(train_data[features],train_data['price'])\n",
    "\n",
    "print('Intercept: {}'.format(complex_model_3.intercept_))\n",
    "print('Coefficients: {}'.format(complex_model_3.coef_))\n",
    "\n",
    "pred = complex_model_3.predict(test_data[features])\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_3.score(train_data[features],train_data['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_3.score(train_data[features],train_data['price']),train_data.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_3.score(test_data[features],test_data['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_3.score(test_data[features],test_data['price']),test_data.shape[0],len(features)),'.3f'))\n",
    "cv = float(format(cross_val_score(complex_model_3,df[features],df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['Multiple Regression-3','all features, no preprocessing',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "evaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8780e30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 8748434.764241785\n",
      "Coefficients: [-3.33491904e+04  3.76549641e+04  1.10716138e+02  1.22826592e-01\n",
      " -1.26725956e+04  5.69817402e+05  5.41386091e+04  3.17275550e+04\n",
      "  9.52300581e+04  7.05367288e+01  4.01795702e+01 -4.46861874e+04\n",
      " -5.43838963e+04 -7.11287025e+04 -8.93583274e+04 -5.92594439e+04\n",
      "  3.70943651e+04  1.22837694e+05  1.58884499e+05 -1.97812401e+04\n",
      "  9.43034022e+04  8.74164248e+04  4.14131931e+04 -1.50309593e+04\n",
      " -1.06990366e+05 -8.13304552e+04 -6.50061210e+02  6.03335811e+05\n",
      " -2.10031732e+05  2.42386074e+01 -3.08651553e-01]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multiple Regression-4</td>\n",
       "      <td>all features</td>\n",
       "      <td>191879.550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiple Regression-3</td>\n",
       "      <td>all features, no preprocessing</td>\n",
       "      <td>193693.989</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multiple Regression-2</td>\n",
       "      <td>selected features</td>\n",
       "      <td>209712.753</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model                         Details  \\\n",
       "4     Multiple Regression-4                    all features   \n",
       "3     Multiple Regression-3  all features, no preprocessing   \n",
       "2     Multiple Regression-2               selected features   \n",
       "1     Multiple Regression-1               selected features   \n",
       "0  Simple Linear Regression                               -   \n",
       "\n",
       "   Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "4                      191879.550                 0.701   \n",
       "3                      193693.989                 0.698   \n",
       "2                      209712.753                 0.652   \n",
       "1                      248514.011                 0.514   \n",
       "0                      254289.149                 0.492   \n",
       "\n",
       "  Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "4                           0.7             0.713                     0.711   \n",
       "3                         0.697             0.708                     0.707   \n",
       "2                         0.652             0.657                     0.656   \n",
       "1                         0.514             0.519                     0.518   \n",
       "0                             -             0.496                         -   \n",
       "\n",
       "   5-Fold Cross Validation  \n",
       "4                    0.698  \n",
       "3                    0.695  \n",
       "2                    0.648  \n",
       "1                    0.512  \n",
       "0                    0.491  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "complex_model_4 = linear_model.LinearRegression()\n",
    "complex_model_4.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "print('Intercept: {}'.format(complex_model_4.intercept_))\n",
    "print('Coefficients: {}'.format(complex_model_4.coef_))\n",
    "\n",
    "pred = complex_model_4.predict(test_data_dm[features])\n",
    "rmsecm = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred)),'.3f'))\n",
    "rtrcm = float(format(complex_model_4.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm = float(format(adjustedR2(complex_model_4.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm = float(format(complex_model_4.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm = float(format(adjustedR2(complex_model_4.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv = float(format(cross_val_score(complex_model_4,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['Multiple Regression-4','all features',rmsecm,rtrcm,artrcm,rtecm,artecm,cv]\n",
    "evaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a301893e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multiple Regression-4</td>\n",
       "      <td>all features</td>\n",
       "      <td>191879.550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1, all features</td>\n",
       "      <td>191903.548</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiple Regression-3</td>\n",
       "      <td>all features, no preprocessing</td>\n",
       "      <td>193693.989</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=100, all features</td>\n",
       "      <td>195372.495</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multiple Regression-2</td>\n",
       "      <td>selected features</td>\n",
       "      <td>209712.753</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1000, all features</td>\n",
       "      <td>209625.468</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Model                         Details  \\\n",
       "4     Multiple Regression-4                    all features   \n",
       "5          Ridge Regression           alpha=1, all features   \n",
       "3     Multiple Regression-3  all features, no preprocessing   \n",
       "6          Ridge Regression         alpha=100, all features   \n",
       "2     Multiple Regression-2               selected features   \n",
       "7          Ridge Regression        alpha=1000, all features   \n",
       "1     Multiple Regression-1               selected features   \n",
       "0  Simple Linear Regression                               -   \n",
       "\n",
       "   Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "4                      191879.550                 0.701   \n",
       "5                      191903.548                 0.701   \n",
       "3                      193693.989                 0.698   \n",
       "6                      195372.495                 0.694   \n",
       "2                      209712.753                 0.652   \n",
       "7                      209625.468                 0.651   \n",
       "1                      248514.011                 0.514   \n",
       "0                      254289.149                 0.492   \n",
       "\n",
       "  Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "4                           0.7             0.713                     0.711   \n",
       "5                           0.7             0.713                     0.711   \n",
       "3                         0.697             0.708                     0.707   \n",
       "6                         0.693             0.703                     0.701   \n",
       "2                         0.652             0.657                     0.656   \n",
       "7                          0.65             0.658                     0.655   \n",
       "1                         0.514             0.519                     0.518   \n",
       "0                             -             0.496                         -   \n",
       "\n",
       "   5-Fold Cross Validation  \n",
       "4                    0.698  \n",
       "5                    0.698  \n",
       "3                    0.695  \n",
       "6                    0.691  \n",
       "2                    0.648  \n",
       "7                    0.648  \n",
       "1                    0.512  \n",
       "0                    0.491  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "complex_model_R = linear_model.Ridge(alpha=1)\n",
    "complex_model_R.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred1 = complex_model_R.predict(test_data_dm[features])\n",
    "rmsecm1 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred1)),'.3f'))\n",
    "rtrcm1 = float(format(complex_model_R.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm1 = float(format(adjustedR2(complex_model_R.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm1 = float(format(complex_model_R.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm1 = float(format(adjustedR2(complex_model_R.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv1 = float(format(cross_val_score(complex_model_R,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "complex_model_R = linear_model.Ridge(alpha=100)\n",
    "complex_model_R.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred2 = complex_model_R.predict(test_data_dm[features])\n",
    "rmsecm2 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred2)),'.3f'))\n",
    "rtrcm2 = float(format(complex_model_R.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm2 = float(format(adjustedR2(complex_model_R.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm2 = float(format(complex_model_R.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm2 = float(format(adjustedR2(complex_model_R.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv2 = float(format(cross_val_score(complex_model_R,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "complex_model_R = linear_model.Ridge(alpha=1000)\n",
    "complex_model_R.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred3 = complex_model_R.predict(test_data_dm[features])\n",
    "rmsecm3 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred3)),'.3f'))\n",
    "rtrcm3 = float(format(complex_model_R.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm3 = float(format(adjustedR2(complex_model_R.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm3 = float(format(complex_model_R.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm3 = float(format(adjustedR2(complex_model_R.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv3 = float(format(cross_val_score(complex_model_R,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['Ridge Regression','alpha=1, all features',rmsecm1,rtrcm1,artrcm1,rtecm1,artecm1,cv1]\n",
    "evaluation.loc[r+1] = ['Ridge Regression','alpha=100, all features',rmsecm2,rtrcm2,artrcm2,rtecm2,artecm2,cv2]\n",
    "evaluation.loc[r+2] = ['Ridge Regression','alpha=1000, all features',rmsecm3,rtrcm3,artrcm3,rtecm3,artecm3,cv3]\n",
    "evaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73161ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multiple Regression-4</td>\n",
       "      <td>all features</td>\n",
       "      <td>191879.550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1, all features</td>\n",
       "      <td>191903.548</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=1, all features</td>\n",
       "      <td>191880.918</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=100, all features</td>\n",
       "      <td>192060.144</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiple Regression-3</td>\n",
       "      <td>all features, no preprocessing</td>\n",
       "      <td>193693.989</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=1000, all features</td>\n",
       "      <td>193587.943</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=100, all features</td>\n",
       "      <td>195372.495</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multiple Regression-2</td>\n",
       "      <td>selected features</td>\n",
       "      <td>209712.753</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1000, all features</td>\n",
       "      <td>209625.468</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model                         Details  \\\n",
       "4      Multiple Regression-4                    all features   \n",
       "5           Ridge Regression           alpha=1, all features   \n",
       "8           Lasso Regression           alpha=1, all features   \n",
       "9           Lasso Regression         alpha=100, all features   \n",
       "3      Multiple Regression-3  all features, no preprocessing   \n",
       "10          Lasso Regression        alpha=1000, all features   \n",
       "6           Ridge Regression         alpha=100, all features   \n",
       "2      Multiple Regression-2               selected features   \n",
       "7           Ridge Regression        alpha=1000, all features   \n",
       "1      Multiple Regression-1               selected features   \n",
       "0   Simple Linear Regression                               -   \n",
       "\n",
       "    Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "4                       191879.550                 0.701   \n",
       "5                       191903.548                 0.701   \n",
       "8                       191880.918                 0.701   \n",
       "9                       192060.144                 0.701   \n",
       "3                       193693.989                 0.698   \n",
       "10                      193587.943                 0.697   \n",
       "6                       195372.495                 0.694   \n",
       "2                       209712.753                 0.652   \n",
       "7                       209625.468                 0.651   \n",
       "1                       248514.011                 0.514   \n",
       "0                       254289.149                 0.492   \n",
       "\n",
       "   Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "4                            0.7             0.713                     0.711   \n",
       "5                            0.7             0.713                     0.711   \n",
       "8                            0.7             0.713                     0.711   \n",
       "9                            0.7             0.713                     0.711   \n",
       "3                          0.697             0.708                     0.707   \n",
       "10                         0.697             0.708                     0.706   \n",
       "6                          0.693             0.703                     0.701   \n",
       "2                          0.652             0.657                     0.656   \n",
       "7                           0.65             0.658                     0.655   \n",
       "1                          0.514             0.519                     0.518   \n",
       "0                              -             0.496                         -   \n",
       "\n",
       "    5-Fold Cross Validation  \n",
       "4                     0.698  \n",
       "5                     0.698  \n",
       "8                     0.698  \n",
       "9                     0.698  \n",
       "3                     0.695  \n",
       "10                    0.695  \n",
       "6                     0.691  \n",
       "2                     0.648  \n",
       "7                     0.648  \n",
       "1                     0.512  \n",
       "0                     0.491  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "complex_model_L = linear_model.Lasso(alpha=1)\n",
    "complex_model_L.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred1 = complex_model_L.predict(test_data_dm[features])\n",
    "rmsecm1 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred1)),'.3f'))\n",
    "rtrcm1 = float(format(complex_model_L.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm1 = float(format(adjustedR2(complex_model_L.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm1 = float(format(complex_model_L.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm1 = float(format(adjustedR2(complex_model_L.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv1 = float(format(cross_val_score(complex_model_L,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "complex_model_L = linear_model.Lasso(alpha=100)\n",
    "complex_model_L.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred2 = complex_model_L.predict(test_data_dm[features])\n",
    "rmsecm2 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred2)),'.3f'))\n",
    "rtrcm2 = float(format(complex_model_L.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm2 = float(format(adjustedR2(complex_model_L.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm2 = float(format(complex_model_L.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm2 = float(format(adjustedR2(complex_model_L.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv2 = float(format(cross_val_score(complex_model_L,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "complex_model_L = linear_model.Lasso(alpha=1000)\n",
    "complex_model_L.fit(train_data_dm[features],train_data_dm['price'])\n",
    "\n",
    "pred3 = complex_model_L.predict(test_data_dm[features])\n",
    "rmsecm3 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred3)),'.3f'))\n",
    "rtrcm3 = float(format(complex_model_L.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrcm3 = float(format(adjustedR2(complex_model_L.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rtecm3 = float(format(complex_model_L.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "artecm3 = float(format(adjustedR2(complex_model_L.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv3 = float(format(cross_val_score(complex_model_L,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['Lasso Regression','alpha=1, all features',rmsecm1,rtrcm1,artrcm1,rtecm1,artecm1,cv1]\n",
    "evaluation.loc[r+1] = ['Lasso Regression','alpha=100, all features',rmsecm2,rtrcm2,artrcm2,rtecm2,artecm2,cv2]\n",
    "evaluation.loc[r+2] = ['Lasso Regression','alpha=1000, all features',rmsecm3,rtrcm3,artrcm3,rtecm3,artecm3,cv3]\n",
    "evaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5250a16b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=2, all features, no preprocessing</td>\n",
       "      <td>151155.989</td>\n",
       "      <td>0.830</td>\n",
       "      <td>0.822</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Polynomial Ridge Regression</td>\n",
       "      <td>alpha=50000, degree=2, all features</td>\n",
       "      <td>159872.571</td>\n",
       "      <td>0.810</td>\n",
       "      <td>0.801</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Polynomial Lasso Regression</td>\n",
       "      <td>alpha=50000, degree=2, all features</td>\n",
       "      <td>166020.484</td>\n",
       "      <td>0.797</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Polynomial Lasso Regression</td>\n",
       "      <td>alpha=1, degree=2, all features</td>\n",
       "      <td>166195.984</td>\n",
       "      <td>0.807</td>\n",
       "      <td>0.785</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=2, selected features, no preprocessing</td>\n",
       "      <td>190980.547</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.716</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=3, selected features, no preprocessing</td>\n",
       "      <td>189235.269</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.721</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=3, all features, no preprocessing</td>\n",
       "      <td>197708.158</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Polynomial Ridge Regression</td>\n",
       "      <td>alpha=1, degree=2, all features</td>\n",
       "      <td>150177.204</td>\n",
       "      <td>0.838</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-3176.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=2, all features</td>\n",
       "      <td>151650.349</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.821</td>\n",
       "      <td>-10874.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Model                                        Details  \\\n",
       "2        Polynomial Regression       degree=2, all features, no preprocessing   \n",
       "6  Polynomial Ridge Regression            alpha=50000, degree=2, all features   \n",
       "8  Polynomial Lasso Regression            alpha=50000, degree=2, all features   \n",
       "7  Polynomial Lasso Regression                alpha=1, degree=2, all features   \n",
       "0        Polynomial Regression  degree=2, selected features, no preprocessing   \n",
       "1        Polynomial Regression  degree=3, selected features, no preprocessing   \n",
       "3        Polynomial Regression       degree=3, all features, no preprocessing   \n",
       "5  Polynomial Ridge Regression                alpha=1, degree=2, all features   \n",
       "4        Polynomial Regression                         degree=2, all features   \n",
       "\n",
       "   Root Mean Squared Error (RMSE)  R-squared (training)  R-squared (test)  \\\n",
       "2                      151155.989                 0.830             0.822   \n",
       "6                      159872.571                 0.810             0.801   \n",
       "8                      166020.484                 0.797             0.785   \n",
       "7                      166195.984                 0.807             0.785   \n",
       "0                      190980.547                 0.730             0.716   \n",
       "1                      189235.269                 0.749             0.721   \n",
       "3                      197708.158                 0.873             0.695   \n",
       "5                      150177.204                 0.838             0.824   \n",
       "4                      151650.349                 0.840             0.821   \n",
       "\n",
       "   5-Fold Cross Validation  \n",
       "2                    0.813  \n",
       "6                    0.791  \n",
       "8                    0.779  \n",
       "7                    0.778  \n",
       "0                    0.714  \n",
       "1                    0.595  \n",
       "3                    0.228  \n",
       "5                -3176.898  \n",
       "4               -10874.012  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_poly = pd.DataFrame({'Model': [],\n",
    "                                'Details':[],\n",
    "                                'Root Mean Squared Error (RMSE)':[],\n",
    "                                'R-squared (training)':[],\n",
    "                                'Adjusted R-squared (training)':[],\n",
    "                                'R-squared (test)':[],\n",
    "                                'Adjusted R-squared (test)':[],\n",
    "                                '5-Fold Cross Validation':[]})\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "             'grade','yr_built','zipcode']\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred1 = poly.predict(X_testpoly)\n",
    "rmsepoly1 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred1)),'.3f'))\n",
    "rtrpoly1 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly1 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv1 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=3)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred2 = poly.predict(X_testpoly)\n",
    "rmsepoly2 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred2)),'.3f'))\n",
    "rtrpoly2 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly2 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv2 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront','view',\n",
    "            'condition','grade','sqft_above','sqft_basement','yr_built','yr_renovated',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred3 = poly.predict(X_testpoly)\n",
    "rmsepoly3 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred3)),'.3f'))\n",
    "rtrpoly3 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly3 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv3 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=3)\n",
    "X_allpoly = polyfeat.fit_transform(df[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred4 = poly.predict(X_testpoly)\n",
    "rmsepoly4 = float(format(np.sqrt(metrics.mean_squared_error(test_data['price'],pred4)),'.3f'))\n",
    "rtrpoly4 = float(format(poly.score(X_trainpoly,train_data['price']),'.3f'))\n",
    "rtepoly4 = float(format(poly.score(X_testpoly,test_data['price']),'.3f'))\n",
    "cv4 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "\n",
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.LinearRegression().fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred5 = poly.predict(X_testpoly)\n",
    "rmsepoly5 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred5)),'.3f'))\n",
    "rtrpoly5 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly5 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv5 = float(format(cross_val_score(linear_model.LinearRegression(),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Ridge(alpha=1).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred6 = poly.predict(X_testpoly)\n",
    "rmsepoly6 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred6)),'.3f'))\n",
    "rtrpoly6 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly6 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv6 = float(format(cross_val_score(linear_model.Ridge(alpha=1),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Ridge(alpha=50000).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred7 = poly.predict(X_testpoly)\n",
    "rmsepoly7 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred7)),'.3f'))\n",
    "rtrpoly7 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly7 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv7 = float(format(cross_val_score(linear_model.Ridge(alpha=50000),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Lasso(alpha=1).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred8 = poly.predict(X_testpoly)\n",
    "rmsepoly8 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred8)),'.3f'))\n",
    "rtrpoly8 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly8 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv8 = float(format(cross_val_score(linear_model.Lasso(alpha=1),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "polyfeat = PolynomialFeatures(degree=2)\n",
    "X_allpoly = polyfeat.fit_transform(df_dm[features])\n",
    "X_trainpoly = polyfeat.fit_transform(train_data_dm[features])\n",
    "X_testpoly = polyfeat.fit_transform(test_data_dm[features])\n",
    "poly = linear_model.Lasso(alpha=50000).fit(X_trainpoly, train_data['price'])\n",
    "\n",
    "pred9 = poly.predict(X_testpoly)\n",
    "rmsepoly9 = float(format(np.sqrt(metrics.mean_squared_error(test_data_dm['price'],pred9)),'.3f'))\n",
    "rtrpoly9 = float(format(poly.score(X_trainpoly,train_data_dm['price']),'.3f'))\n",
    "rtepoly9 = float(format(poly.score(X_testpoly,test_data_dm['price']),'.3f'))\n",
    "cv9 = float(format(cross_val_score(linear_model.Lasso(alpha=50000),X_allpoly,df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation_poly.shape[0]\n",
    "evaluation_poly.loc[r] = ['Polynomial Regression','degree=2, selected features, no preprocessing',rmsepoly1,rtrpoly1,'-',rtepoly1,'-',cv1]\n",
    "evaluation_poly.loc[r+1] = ['Polynomial Regression','degree=3, selected features, no preprocessing',rmsepoly2,rtrpoly2,'-',rtepoly2,'-',cv2]\n",
    "evaluation_poly.loc[r+2] = ['Polynomial Regression','degree=2, all features, no preprocessing',rmsepoly3,rtrpoly3,'-',rtepoly3,'-',cv3]\n",
    "evaluation_poly.loc[r+3] = ['Polynomial Regression','degree=3, all features, no preprocessing',rmsepoly4,rtrpoly4,'-',rtepoly4,'-',cv4]\n",
    "evaluation_poly.loc[r+4] = ['Polynomial Regression','degree=2, all features',rmsepoly5,rtrpoly5,'-',rtepoly5,'-',cv5]\n",
    "evaluation_poly.loc[r+5] = ['Polynomial Ridge Regression','alpha=1, degree=2, all features',rmsepoly6,rtrpoly6,'-',rtepoly6,'-',cv6]\n",
    "evaluation_poly.loc[r+6] = ['Polynomial Ridge Regression','alpha=50000, degree=2, all features',rmsepoly7,rtrpoly7,'-',rtepoly7,'-',cv7]\n",
    "evaluation_poly.loc[r+7] = ['Polynomial Lasso Regression','alpha=1, degree=2, all features',rmsepoly8,rtrpoly8,'-',rtepoly8,'-',cv8]\n",
    "evaluation_poly.loc[r+8] = ['Polynomial Lasso Regression','alpha=50000, degree=2, all features',rmsepoly9,rtrpoly9,'-',rtepoly9,'-',cv9]\n",
    "evaluation_poly_temp = evaluation_poly[['Model','Details','Root Mean Squared Error (RMSE)','R-squared (training)','R-squared (test)','5-Fold Cross Validation']]\n",
    "evaluation_poly_temp.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "053fda56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Multiple Regression-4</td>\n",
       "      <td>all features</td>\n",
       "      <td>191879.550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1, all features</td>\n",
       "      <td>191903.548</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=1, all features</td>\n",
       "      <td>191880.918</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=100, all features</td>\n",
       "      <td>192060.144</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Multiple Regression-3</td>\n",
       "      <td>all features, no preprocessing</td>\n",
       "      <td>193693.989</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=1000, all features</td>\n",
       "      <td>193587.943</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=100, all features</td>\n",
       "      <td>195372.495</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multiple Regression-2</td>\n",
       "      <td>selected features</td>\n",
       "      <td>209712.753</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1000, all features</td>\n",
       "      <td>209625.468</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>k=15, all features</td>\n",
       "      <td>242835.936</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>k=25, all features</td>\n",
       "      <td>247034.211</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>k=27, all features</td>\n",
       "      <td>247416.169</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Model                         Details  \\\n",
       "4      Multiple Regression-4                    all features   \n",
       "5           Ridge Regression           alpha=1, all features   \n",
       "8           Lasso Regression           alpha=1, all features   \n",
       "9           Lasso Regression         alpha=100, all features   \n",
       "3      Multiple Regression-3  all features, no preprocessing   \n",
       "10          Lasso Regression        alpha=1000, all features   \n",
       "6           Ridge Regression         alpha=100, all features   \n",
       "2      Multiple Regression-2               selected features   \n",
       "7           Ridge Regression        alpha=1000, all features   \n",
       "1      Multiple Regression-1               selected features   \n",
       "11            KNN Regression              k=15, all features   \n",
       "0   Simple Linear Regression                               -   \n",
       "12            KNN Regression              k=25, all features   \n",
       "13            KNN Regression              k=27, all features   \n",
       "\n",
       "    Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "4                       191879.550                 0.701   \n",
       "5                       191903.548                 0.701   \n",
       "8                       191880.918                 0.701   \n",
       "9                       192060.144                 0.701   \n",
       "3                       193693.989                 0.698   \n",
       "10                      193587.943                 0.697   \n",
       "6                       195372.495                 0.694   \n",
       "2                       209712.753                 0.652   \n",
       "7                       209625.468                 0.651   \n",
       "1                       248514.011                 0.514   \n",
       "11                      242835.936                 0.562   \n",
       "0                       254289.149                 0.492   \n",
       "12                      247034.211                 0.529   \n",
       "13                      247416.169                 0.523   \n",
       "\n",
       "   Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "4                            0.7             0.713                     0.711   \n",
       "5                            0.7             0.713                     0.711   \n",
       "8                            0.7             0.713                     0.711   \n",
       "9                            0.7             0.713                     0.711   \n",
       "3                          0.697             0.708                     0.707   \n",
       "10                         0.697             0.708                     0.706   \n",
       "6                          0.693             0.703                     0.701   \n",
       "2                          0.652             0.657                     0.656   \n",
       "7                           0.65             0.658                     0.655   \n",
       "1                          0.514             0.519                     0.518   \n",
       "11                         0.561             0.541                     0.537   \n",
       "0                              -             0.496                         -   \n",
       "12                         0.528             0.525                     0.521   \n",
       "13                         0.522             0.523                      0.52   \n",
       "\n",
       "    5-Fold Cross Validation  \n",
       "4                     0.698  \n",
       "5                     0.698  \n",
       "8                     0.698  \n",
       "9                     0.698  \n",
       "3                     0.695  \n",
       "10                    0.695  \n",
       "6                     0.691  \n",
       "2                     0.648  \n",
       "7                     0.648  \n",
       "1                     0.512  \n",
       "11                    0.496  \n",
       "0                     0.491  \n",
       "12                    0.487  \n",
       "13                    0.486  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['bedrooms','bathrooms','sqft_living','sqft_lot','floors','waterfront',\n",
    "            'view','condition','grade','sqft_above','sqft_basement','age_binned_<1', \n",
    "            'age_binned_1-5', 'age_binned_6-10','age_binned_11-25', 'age_binned_26-50',\n",
    "            'age_binned_51-75','age_binned_76-100', 'age_binned_>100','age_rnv_binned_<1',\n",
    "            'age_rnv_binned_1-5', 'age_rnv_binned_6-10', 'age_rnv_binned_11-25',\n",
    "            'age_rnv_binned_26-50', 'age_rnv_binned_51-75', 'age_rnv_binned_>75',\n",
    "            'zipcode','lat','long','sqft_living15','sqft_lot15']\n",
    "knnreg = KNeighborsRegressor(n_neighbors=15)\n",
    "knnreg.fit(train_data_dm[features],train_data_dm['price'])\n",
    "pred = knnreg.predict(test_data_dm[features])\n",
    "\n",
    "rmseknn1 = float(format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f'))\n",
    "rtrknn1 = float(format(knnreg.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrknn1 = float(format(adjustedR2(knnreg.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rteknn1 = float(format(knnreg.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "arteknn1 = float(format(adjustedR2(knnreg.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv1 = float(format(cross_val_score(knnreg,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "knnreg = KNeighborsRegressor(n_neighbors=25)\n",
    "knnreg.fit(train_data_dm[features],train_data_dm['price'])\n",
    "pred = knnreg.predict(test_data_dm[features])\n",
    "\n",
    "rmseknn2 = float(format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f'))\n",
    "rtrknn2 = float(format(knnreg.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrknn2 = float(format(adjustedR2(knnreg.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rteknn2 = float(format(knnreg.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "arteknn2 = float(format(adjustedR2(knnreg.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv2 = float(format(cross_val_score(knnreg,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "knnreg = KNeighborsRegressor(n_neighbors=27)\n",
    "knnreg.fit(train_data_dm[features],train_data_dm['price'])\n",
    "pred = knnreg.predict(test_data_dm[features])\n",
    "\n",
    "rmseknn3 = float(format(np.sqrt(metrics.mean_squared_error(y_test,pred)),'.3f'))\n",
    "rtrknn3 = float(format(knnreg.score(train_data_dm[features],train_data_dm['price']),'.3f'))\n",
    "artrknn3 = float(format(adjustedR2(knnreg.score(train_data_dm[features],train_data_dm['price']),train_data_dm.shape[0],len(features)),'.3f'))\n",
    "rteknn3 = float(format(knnreg.score(test_data_dm[features],test_data_dm['price']),'.3f'))\n",
    "arteknn3 = float(format(adjustedR2(knnreg.score(test_data_dm[features],test_data_dm['price']),test_data_dm.shape[0],len(features)),'.3f'))\n",
    "cv3 = float(format(cross_val_score(knnreg,df_dm[features],df_dm['price'],cv=5).mean(),'.3f'))\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['KNN Regression','k=15, all features',rmseknn1,rtrknn1,artrknn1,rteknn1,arteknn1,cv1]\n",
    "evaluation.loc[r+1] = ['KNN Regression','k=25, all features',rmseknn2,rtrknn2,artrknn2,rteknn2,arteknn2,cv2]\n",
    "evaluation.loc[r+2] = ['KNN Regression','k=27, all features',rmseknn3,rtrknn3,artrknn3,rteknn3,arteknn3,cv3]\n",
    "evaluation.sort_values(by = '5-Fold Cross Validation', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "36412db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Details</th>\n",
       "      <th>Root Mean Squared Error (RMSE)</th>\n",
       "      <th>R-squared (training)</th>\n",
       "      <th>Adjusted R-squared (training)</th>\n",
       "      <th>R-squared (test)</th>\n",
       "      <th>Adjusted R-squared (test)</th>\n",
       "      <th>5-Fold Cross Validation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=2, all features, no preprocessing</td>\n",
       "      <td>151155.989</td>\n",
       "      <td>0.830</td>\n",
       "      <td>-</td>\n",
       "      <td>0.822</td>\n",
       "      <td>-</td>\n",
       "      <td>0.813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Polynomial Ridge Regression</td>\n",
       "      <td>alpha=50000, degree=2, all features</td>\n",
       "      <td>159872.571</td>\n",
       "      <td>0.810</td>\n",
       "      <td>-</td>\n",
       "      <td>0.801</td>\n",
       "      <td>-</td>\n",
       "      <td>0.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Polynomial Lasso Regression</td>\n",
       "      <td>alpha=50000, degree=2, all features</td>\n",
       "      <td>166020.484</td>\n",
       "      <td>0.797</td>\n",
       "      <td>-</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-</td>\n",
       "      <td>0.779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Polynomial Lasso Regression</td>\n",
       "      <td>alpha=1, degree=2, all features</td>\n",
       "      <td>166195.984</td>\n",
       "      <td>0.807</td>\n",
       "      <td>-</td>\n",
       "      <td>0.785</td>\n",
       "      <td>-</td>\n",
       "      <td>0.778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=2, selected features, no preprocessing</td>\n",
       "      <td>190980.547</td>\n",
       "      <td>0.730</td>\n",
       "      <td>-</td>\n",
       "      <td>0.716</td>\n",
       "      <td>-</td>\n",
       "      <td>0.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Multiple Regression-4</td>\n",
       "      <td>all features</td>\n",
       "      <td>191879.550</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1, all features</td>\n",
       "      <td>191903.548</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=1, all features</td>\n",
       "      <td>191880.918</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=100, all features</td>\n",
       "      <td>192060.144</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.713</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Multiple Regression-3</td>\n",
       "      <td>all features, no preprocessing</td>\n",
       "      <td>193693.989</td>\n",
       "      <td>0.698</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.707</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Lasso Regression</td>\n",
       "      <td>alpha=1000, all features</td>\n",
       "      <td>193587.943</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.697</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=100, all features</td>\n",
       "      <td>195372.495</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.693</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.701</td>\n",
       "      <td>0.691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Multiple Regression-2</td>\n",
       "      <td>selected features</td>\n",
       "      <td>209712.753</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.657</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Ridge Regression</td>\n",
       "      <td>alpha=1000, all features</td>\n",
       "      <td>209625.468</td>\n",
       "      <td>0.651</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.658</td>\n",
       "      <td>0.655</td>\n",
       "      <td>0.648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=3, selected features, no preprocessing</td>\n",
       "      <td>189235.269</td>\n",
       "      <td>0.749</td>\n",
       "      <td>-</td>\n",
       "      <td>0.721</td>\n",
       "      <td>-</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Multiple Regression-1</td>\n",
       "      <td>selected features</td>\n",
       "      <td>248514.011</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.514</td>\n",
       "      <td>0.519</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>k=15, all features</td>\n",
       "      <td>242835.936</td>\n",
       "      <td>0.562</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.537</td>\n",
       "      <td>0.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Simple Linear Regression</td>\n",
       "      <td>-</td>\n",
       "      <td>254289.149</td>\n",
       "      <td>0.492</td>\n",
       "      <td>-</td>\n",
       "      <td>0.496</td>\n",
       "      <td>-</td>\n",
       "      <td>0.491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>k=25, all features</td>\n",
       "      <td>247034.211</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.525</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>KNN Regression</td>\n",
       "      <td>k=27, all features</td>\n",
       "      <td>247416.169</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=3, all features, no preprocessing</td>\n",
       "      <td>197708.158</td>\n",
       "      <td>0.873</td>\n",
       "      <td>-</td>\n",
       "      <td>0.695</td>\n",
       "      <td>-</td>\n",
       "      <td>0.228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Polynomial Ridge Regression</td>\n",
       "      <td>alpha=1, degree=2, all features</td>\n",
       "      <td>150177.204</td>\n",
       "      <td>0.838</td>\n",
       "      <td>-</td>\n",
       "      <td>0.824</td>\n",
       "      <td>-</td>\n",
       "      <td>-3176.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Polynomial Regression</td>\n",
       "      <td>degree=2, all features</td>\n",
       "      <td>151650.349</td>\n",
       "      <td>0.840</td>\n",
       "      <td>-</td>\n",
       "      <td>0.821</td>\n",
       "      <td>-</td>\n",
       "      <td>-10874.012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Model  \\\n",
       "0         Polynomial Regression   \n",
       "1   Polynomial Ridge Regression   \n",
       "2   Polynomial Lasso Regression   \n",
       "3   Polynomial Lasso Regression   \n",
       "4         Polynomial Regression   \n",
       "5         Multiple Regression-4   \n",
       "6              Ridge Regression   \n",
       "7              Lasso Regression   \n",
       "8              Lasso Regression   \n",
       "9         Multiple Regression-3   \n",
       "10             Lasso Regression   \n",
       "11             Ridge Regression   \n",
       "12        Multiple Regression-2   \n",
       "13             Ridge Regression   \n",
       "14        Polynomial Regression   \n",
       "15        Multiple Regression-1   \n",
       "16               KNN Regression   \n",
       "17     Simple Linear Regression   \n",
       "18               KNN Regression   \n",
       "19               KNN Regression   \n",
       "20        Polynomial Regression   \n",
       "21  Polynomial Ridge Regression   \n",
       "22        Polynomial Regression   \n",
       "\n",
       "                                          Details  \\\n",
       "0        degree=2, all features, no preprocessing   \n",
       "1             alpha=50000, degree=2, all features   \n",
       "2             alpha=50000, degree=2, all features   \n",
       "3                 alpha=1, degree=2, all features   \n",
       "4   degree=2, selected features, no preprocessing   \n",
       "5                                    all features   \n",
       "6                           alpha=1, all features   \n",
       "7                           alpha=1, all features   \n",
       "8                         alpha=100, all features   \n",
       "9                  all features, no preprocessing   \n",
       "10                       alpha=1000, all features   \n",
       "11                        alpha=100, all features   \n",
       "12                              selected features   \n",
       "13                       alpha=1000, all features   \n",
       "14  degree=3, selected features, no preprocessing   \n",
       "15                              selected features   \n",
       "16                             k=15, all features   \n",
       "17                                              -   \n",
       "18                             k=25, all features   \n",
       "19                             k=27, all features   \n",
       "20       degree=3, all features, no preprocessing   \n",
       "21                alpha=1, degree=2, all features   \n",
       "22                         degree=2, all features   \n",
       "\n",
       "    Root Mean Squared Error (RMSE)  R-squared (training)  \\\n",
       "0                       151155.989                 0.830   \n",
       "1                       159872.571                 0.810   \n",
       "2                       166020.484                 0.797   \n",
       "3                       166195.984                 0.807   \n",
       "4                       190980.547                 0.730   \n",
       "5                       191879.550                 0.701   \n",
       "6                       191903.548                 0.701   \n",
       "7                       191880.918                 0.701   \n",
       "8                       192060.144                 0.701   \n",
       "9                       193693.989                 0.698   \n",
       "10                      193587.943                 0.697   \n",
       "11                      195372.495                 0.694   \n",
       "12                      209712.753                 0.652   \n",
       "13                      209625.468                 0.651   \n",
       "14                      189235.269                 0.749   \n",
       "15                      248514.011                 0.514   \n",
       "16                      242835.936                 0.562   \n",
       "17                      254289.149                 0.492   \n",
       "18                      247034.211                 0.529   \n",
       "19                      247416.169                 0.523   \n",
       "20                      197708.158                 0.873   \n",
       "21                      150177.204                 0.838   \n",
       "22                      151650.349                 0.840   \n",
       "\n",
       "   Adjusted R-squared (training)  R-squared (test) Adjusted R-squared (test)  \\\n",
       "0                              -             0.822                         -   \n",
       "1                              -             0.801                         -   \n",
       "2                              -             0.785                         -   \n",
       "3                              -             0.785                         -   \n",
       "4                              -             0.716                         -   \n",
       "5                            0.7             0.713                     0.711   \n",
       "6                            0.7             0.713                     0.711   \n",
       "7                            0.7             0.713                     0.711   \n",
       "8                            0.7             0.713                     0.711   \n",
       "9                          0.697             0.708                     0.707   \n",
       "10                         0.697             0.708                     0.706   \n",
       "11                         0.693             0.703                     0.701   \n",
       "12                         0.652             0.657                     0.656   \n",
       "13                          0.65             0.658                     0.655   \n",
       "14                             -             0.721                         -   \n",
       "15                         0.514             0.519                     0.518   \n",
       "16                         0.561             0.541                     0.537   \n",
       "17                             -             0.496                         -   \n",
       "18                         0.528             0.525                     0.521   \n",
       "19                         0.522             0.523                      0.52   \n",
       "20                             -             0.695                         -   \n",
       "21                             -             0.824                         -   \n",
       "22                             -             0.821                         -   \n",
       "\n",
       "    5-Fold Cross Validation  \n",
       "0                     0.813  \n",
       "1                     0.791  \n",
       "2                     0.779  \n",
       "3                     0.778  \n",
       "4                     0.714  \n",
       "5                     0.698  \n",
       "6                     0.698  \n",
       "7                     0.698  \n",
       "8                     0.698  \n",
       "9                     0.695  \n",
       "10                    0.695  \n",
       "11                    0.691  \n",
       "12                    0.648  \n",
       "13                    0.648  \n",
       "14                    0.595  \n",
       "15                    0.512  \n",
       "16                    0.496  \n",
       "17                    0.491  \n",
       "18                    0.487  \n",
       "19                    0.486  \n",
       "20                    0.228  \n",
       "21                -3176.898  \n",
       "22               -10874.012  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation_temp=evaluation.append(evaluation_poly)\n",
    "evaluation_temp1=evaluation_temp.sort_values(by = '5-Fold Cross Validation', ascending=False)\n",
    "evaluation_temp2=evaluation_temp1.reset_index()\n",
    "evaluation_f=evaluation_temp2.iloc[:,1:]\n",
    "evaluation_f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
